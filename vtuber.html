<!DOCTYPE html>
<html lang="ko">
<head>
<meta charset="UTF-8">
<title>VTuber Face Tracking</title>

<style>
  body { margin:0; overflow:hidden; background:#111; }
  #video {
    position:fixed; right:10px; bottom:10px;
    width:160px; opacity:0.15; z-index:10;
  }

  #avatarWrap {
    position:absolute;
    left:50%; top:50%;
    transform:translate(-50%, -50%);
    width:420px;
    transform-style:preserve-3d;
  }

  #avatar {
    width:100%;
    transform-origin:center center;
  }

  /* 말하기(입 움직임) */
  #mouth {
    position:absolute;
    left:0; right:0;
    margin:auto;
    bottom:18%;
    width:50%;
    height:60px;
    background:rgba(0,0,0,0);
    transform-origin:top center;
  }

  /* 눈 깜빡임(가상 눈 애니메이션 영역) */
  #eyeL, #eyeR {
    position:absolute;
    width:70px;
    height:40px;
    background:rgba(0,0,0,0);
    transform-origin:center center;
  }
  #eyeL { left:27%; top:33%; }
  #eyeR { right:27%; top:33%; }

  #startBtn {
    position:fixed; top:20px; left:20px; z-index:100;
    padding:10px 18px; font-size:16px;
  }
</style>

<!-- MediaPipe -->
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/facemesh"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>

</head>
<body>

<button id="startBtn">카메라 켜기</button>

<video id="video" autoplay playsinline></video>

<div id="avatarWrap">
  <img id="avatar" src="https://i.postimg.cc/4N1FGDnL/20250316-082410-IMG-0039.png" crossorigin="anonymous">

  <!-- "가상" 눈/입 layer -->
  <div id="eyeL"></div>
  <div id="eyeR"></div>
  <div id="mouth"></div>
</div>

<script>
const video = document.getElementById("video");
const avatarWrap = document.getElementById("avatarWrap");
const eyeL = document.getElementById("eyeL");
const eyeR = document.getElementById("eyeR");
const mouth = document.getElementById("mouth");

// ------------ 카메라 시작 --------------------
document.getElementById("startBtn").onclick = async () => {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: "user" }
    });
    video.srcObject = stream;
    initFaceMesh();
    alert("카메라 켜짐!");
  } catch (e) {
    alert("카메라 접근 실패: " + e);
  }
};

// ------------ FaceMesh 시작 ------------------
function initFaceMesh() {
  const faceMesh = new FaceMesh.FaceMesh({
    locateFile: (file) =>
      `https://cdn.jsdelivr.net/npm/@mediapipe/facemesh/${file}`
  });

  faceMesh.setOptions({
    selfieMode: true,
    maxNumFaces: 1,
    refineLandmarks: true,
    minDetectionConfidence: 0.5,
    minTrackingConfidence: 0.5
  });

  faceMesh.onResults(onResults);

  const camera = new CameraUtils.Camera(video, {
    onFrame: async () => { await faceMesh.send({image: video}); },
    width: 640, height: 480
  });
  camera.start();
}

// ------------ 얼굴 결과 처리 ------------------
function onResults(res) {
  if (!res.multiFaceLandmarks[0]) return;

  const lm = res.multiFaceLandmarks[0];

  // EAR 계산 (눈 깜빡임)
  const blinkL = calcEAR(lm[159], lm[145], lm[133], lm[246]);
  const blinkR = calcEAR(lm[386], lm[374], lm[362], lm[263]);

  // 입 거리 계산
  const mouthOpen = distance(lm[13], lm[14]);

  // 얼굴 좌우 회전 (yaw)
  const yaw = (lm[33].x - lm[263].x) * 400;

  // 얼굴 상하 회전 (pitch)
  const pitch = (lm[1].y - lm[152].y) * 300;

  // --- 머리 회전 적용 ---
  avatarWrap.style.transform =
    `translate(-50%, -50%) rotateY(${-yaw}deg) rotateX(${pitch}deg)`;

  // --- 눈 깜빡임 적용 ---
  eyeL.style.transform = `scaleY(${blinkL})`;
  eyeR.style.transform = `scaleY(${blinkR})`;

  // --- 입 움직임 적용 ---
  let mouthScale = Math.min(Math.max(mouthOpen * 25, 1), 2.2);
  mouth.style.transform = `scaleY(${mouthScale})`;
}

// ------------ 유틸리티 -----------------------
function distance(p1, p2) {
  return Math.sqrt(
    Math.pow(p1.x - p2.x, 2) +
    Math.pow(p1.y - p2.y, 2)
  );
}

// EAR → scale 변환
function calcEAR(pUp, pDown, pLeft, pRight) {
  const vDist = distance(pUp, pDown);
  let scale = vDist * 60;
  return Math.min(Math.max(scale, 0.1), 1);
}
</script>

</body>
</html>
